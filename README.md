# Machine-Learning-Note(机器学习笔记)

## 机器学习“判定模型”和“生成模型”有什么区别？
假设我们有两类动物，大象（y = 1）和狗（y = 0）。而X是动物的特征向量。

给定训练集，诸如逻辑回归或支持向量机算法之类的算法会尝试找到一条将大象和狗分开的直线（即决策边界）。然后，要将新动物归类为大象或狗，它会检查它落在决策边界的哪一侧，并据此做出预测。我们称这些判别学习算法。p(y|x)条件概率。

另一种方法，首先，看看大象，我们可以建立一个大象长什么样的模型。然后，查看狗，我们可以为狗的外观建立一个单独的模型。最后，要对新动物进行分类，我们可以将新动物与大象模型进行匹配，并与狗模型进行匹配，以查看新动物看起来更像大象还是更像我们在训练集中看到的狗。我们称这些生成学习算法。p(x,y)联合概率。


## 理解支持向量机
形式上，支持向量机在高维或无限维空间中构建一个超平面或一组超平面，可用于分类，回归或其他任务。
直观地，通过超平面可以实现良好的分离，该超平面与任何类别的最近训练数据点之间的距离最大（所谓的功能裕量），因为通常裕量越大，分类器分类器的泛化误差就越小。

通常与“内核函数”一起使用，本质上是对有效地使空间非线性化的标准内部产品的替代。这大致相当于从你的空间到应用线性分类器的某个“工作空间”中进行非线性变换，然后将结果拉回到您的原始空间，在该原始空间中，分类器使用的线性子空间不再是线性的。

支持向量机使用内核函数将数据隐式映射到可以线性分离的特征空间中：
![支持向量机_1.jpg](./image/支持向量机_1.jpg)
